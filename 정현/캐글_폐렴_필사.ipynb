{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2bf491f",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/madz2000/pneumonia-detection-using-cnn-92-6-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "for dirname, _ , filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames :\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyploy as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BathchNormalization\n",
    "from keras .preprocessing,image import ImageDateGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"PENUMONIA\", \"NORMAL\"]\n",
    "img_size = 150\n",
    "def get_training_data(data_dir) :\n",
    "    data = []\n",
    "        for lavel in labels :\n",
    "        path = os.path.join(data_dir, label)\n",
    "        for img in os.listdir(path) :\n",
    "            try :\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                \n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e :\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_training_data(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/train\")\n",
    "test = get_training_data(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/test\")\n",
    "val = get_training_data(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ce04f",
   "metadata": {},
   "source": [
    "# Data Visualization & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac07cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in train :\n",
    "    if(i[1] ==0):\n",
    "        l.append(\"Pneumonia\")\n",
    "    else :\n",
    "        l.append(\"Normal\")\n",
    "sns.set_style(\"darkgird\")\n",
    "sns.countplot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d564d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(train[0][0], cmap='gray')\n",
    "plt.title(labels[train[0][1]])\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(train[-1][0], cmap='gray')\n",
    "plt.title(labels[train[-1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "for feature, label in train :\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "    \n",
    "for feature, label in test :\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)\n",
    "    \n",
    "for feature, label in val :\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1152981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "x_test = np.array(x_test)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a34992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize data for deep learning \n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_testl = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694beb1b",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f561e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강을 통해 과적합과 데이터 불균형을 막고자 한다.\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "samplewise_center = False,\n",
    "featurewise_std_noramlization = False,\n",
    "samplewise_std_normalization = False, # \n",
    "zca_whitening = False, # ZCA Whitening  \n",
    "rotation_range = 30, # 랜덤하게 회전\n",
    "zoom_range = 0.2, # 랜덤하게 줌\n",
    "width_shift_range = 0.1, # 랜덤하게 수평이동\n",
    "height_shift_range = 0.1, # 랜덤하게 수직이동\n",
    "horizontal_flip = True, # 랜덤하게 좌우 반전\n",
    "vertical_flip = False)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e4b6ee",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a071b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
    "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reducation = ReduceLROnPlateau(monitor = 'val_accuracy', \n",
    "                                             patience =2 , verbose = 1,\n",
    "                                             factor = 0.3, min_lr = 0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(x_train, y_train, batch_size = 32), \n",
    "                    epochs = 12, validation_data = datagen.flow(x_val, y_val), \n",
    "                    callbacks = [learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ebadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c4f8c",
   "metadata": {},
   "source": [
    "# Analysis after Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(12)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n",
    "ax[1].set_title('Testing Accuracy & Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Training & Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7df2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "predictions[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a21126",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06232a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' ,\n",
    "            linewidth = 1 , annot = True, \n",
    "            fmt='',xticklabels = labels,yticklabels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff202939",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.nonzero(predictions == y_test)[0]\n",
    "incorrect = np.nonzero(predictions != y_test)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (NGC 22.09 / TensorFlow 2.9.1) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
