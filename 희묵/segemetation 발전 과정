출처: [https://www.youtube.com/watch?v=sbcC6N5xfy8](https://www.youtube.com/watch?v=sbcC6N5xfy8)

### **Segmentation 이란?**

- Object Detection → bbox 단위
- Image Segmentation → bbox 안의 실제 영역까지 찾음

### **Segmentation 의 발전**

1. R-CNN : 여기서 R : Region 
    - 주요 객체들을 bbox 로 표현하여 정확히 식별하는 게 목표
    
    ![bbox 로 객체 탐지 → 정사각형 모양으로 warp (그 당시 imagenet 이 정사각형 모양의 이미지를 사용했기 때문에) → CNN ](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b32f0a90-be77-4e83-9c74-8a4e7219cffe/Untitled.png)
    
    bbox 로 객체 탐지 → 정사각형 모양으로 warp (그 당시 imagenet 이 정사각형 모양의 이미지를 사용했기 때문에) → CNN 
    
2. Fast R-CNN
    - ROI(Region of Interest) 풀링을 통해 한 이미지의 subregion에 대한 forward pass 값을 공유 → R-CNN의 단점인 느린 속도를 빠른 속도로 개선
    - R-CNN은 CNN 모델로 image feature를 추출, SVM 모델로 분류, Regressor 모델로 bounding box를 맞추는 작업으로 분류되어 있지만, Fast R-CNN은 하나의 모델로 동작
    
    ![Fast R-CNN은 하나의 모델로 동작 : Top layer에 softmax layer 를 둬서 CNN 결과를 class 로 출력 + Box regression layer 를 softmax laye r에 평행하게 두어 bounding box 좌표를 출력](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0140129d-db15-4955-b121-839547bfff1e/Untitled.png)
    
    Fast R-CNN은 하나의 모델로 동작 : Top layer에 softmax layer 를 둬서 CNN 결과를 class 로 출력 + Box regression layer 를 softmax laye r에 평행하게 두어 bounding box 좌표를 출력
    
3. Faster R-CNN
    - Fast R-CNN은 가능성 있는 다양한 bounding box들, 즉 ROI를 생성하는 과정인 selective search가 느려 region proposer에서 병목이 발생
    - 이미지 분류(classification)의 첫 단계인 CNN의 forward pass를 통해 얻어진 feature들을 기반으로 영역을 제안
    
    ![CNN 결과를 selective search 알고리즘 대신 region proposal에 이용](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/08755e94-ef08-4f72-879b-dcb8d4f96f03/Untitled.png)
    
    CNN 결과를 selective search 알고리즘 대신 region proposal에 이용
    
    - k개의 일반적인 비율을 지닌 anchor box를 이용하여 하나의 bounding box 및 score를 이미지의 위치별로 출력
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7723615a-6bb7-4129-bf32-ac77b95dc43d/Untitled.png)
    
4. Mask R-CNN
    - Pixel 레벨의 세그멘테이션
    - RolPool에서 선택된 feature map이 원래 이미지 영역으로 약간 잘못된 정렬이 발생한 부분을 RolAlign을 통해 조정하여 정확하게 정렬
    - Mask R-CNN은 Mask가 생성되면, Faster R-CNN으로 생성된 classification과 bounding box들을 합쳐 정확한 세그멘테이션 가능
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3abdeed6-d380-46d7-bd6c-1e84c7b10abe/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5e3f7340-814b-40ca-ae31-bc8228ca16dd/Untitled.png)
    

### **U-Net 기반 세그멘테이션**

- biomedical 이미지를 segmentation 하는데 U-Net 모델 탄생
- U-Net이라 불리는 인코더(다운샘플링)와 디코더(업샘플링)를 포함한 구조는 정교한 픽셀 단위의 segmentation이 요구되는 biomedical image segmentation task의 핵심 요소
- Encoder-decoder 구조 또한 semantic segmentation을 위한 CNN 구조로 자주 활용
- Encoder 부분에서는 점진적으로 spatial dimension을 줄여가면서 고차원의 semantic 정보를 convolution filter가 추출해낼 수 있게 함
- Decoder 부분에서는 encoder에서 spatial dimension 축소로 인해 손실된 spatial 정보를 점진적으로 복원하여 보다 정교한 boundary segmentation을 완성
- U-Net은 기본적인 encoder-decoder 구조와 달리 Spatial 정보를 복원하는 과정에서 이전 encoder feature map 중 동일한 크기를 지닌 feature map을 가져 와 prior로 활용함으로써 더 정확한 boundary segmentation이 가능하게 함
